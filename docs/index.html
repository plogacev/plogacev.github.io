<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Pavel Logaƒçev">
<meta name="description" content="In-depth data science case studies demonstrating Bayesian methods, time series analysis, changepoint detection, and LLM applications.">

<title>Pavel Logaƒçev - Technical Case Studies</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a3c678dfcaee15683ca67e3784a3a6e9.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<meta property="og:title" content="Pavel Logaƒçev - Freelance Data Scientist">
<meta property="og:description" content="Freelance data scientist specializing in statistical modeling, Bayesian methods, demand modeling, price elasticity, and causal inference. Based in Berlin.">
<meta property="og:image" content="https://plogacev.github.io/assets/images/pavel.png">
<meta property="og:site_name" content="Pavel Logaƒçev">
<meta property="og:image:height" content="1440">
<meta property="og:image:width" content="1440">
<meta property="og:image:alt" content="Pavel Logaƒçev - Freelance Data Scientist">
<meta name="twitter:title" content="Pavel Logaƒçev - Freelance Data Scientist">
<meta name="twitter:description" content="Freelance data scientist specializing in statistical modeling, Bayesian methods, demand modeling, price elasticity, and causal inference. Based in Berlin.">
<meta name="twitter:image" content="https://plogacev.github.io/assets/images/pavel.png">
<meta name="twitter:image-height" content="1440">
<meta name="twitter:image-width" content="1440">
<meta name="twitter:image:alt" content="Pavel Logaƒçev - Freelance Data Scientist">
<meta name="twitter:card" content="summary_large_image">
</head><body class="nav-fixed quarto-light"><p><link rel="stylesheet" href="assets/contact.css"></p>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Person",
  "name": "Pavel Logaƒçev",
  "jobTitle": "Freelance Data Scientist",
  "description": "Freelance data scientist specializing in statistical modeling, Bayesian methods, demand modeling, price elasticity, and causal inference.",
  "url": "https://plogacev.github.io",
  "image": "https://plogacev.github.io/assets/images/pavel.png",
  "sameAs": [
    "https://www.linkedin.com/in/pavel-logacev",
    "https://github.com/plogacev"
  ],
  "knowsAbout": [
    "Data Science",
    "Statistical Modeling",
    "Bayesian Methods",
    "Demand Modeling",
    "Price Elasticity",
    "Causal Inference",
    "Forecasting",
    "Machine Learning"
  ],
  "alumniOf": {
    "@type": "CollegeOrUniversity",
    "name": "University of Potsdam"
  },
  "hasCredential": {
    "@type": "EducationalOccupationalCredential",
    "credentialCategory": "PhD",
    "about": "Cognitive Science"
  },
  "address": {
    "@type": "PostalAddress",
    "addressLocality": "Berlin",
    "addressCountry": "Germany"
  }
}
</script>
<link rel="stylesheet" href="assets/css/index.css">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>





<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Pavel Logaƒçev</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="./about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./projects/index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./case-studies/index.html"> 
<span class="menu-text">Case Studies</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./contact.html"> 
<span class="menu-text">Contact</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://github.com/plogacev" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
    <a href="https://www.linkedin.com/in/pavel-logacev" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-linkedin"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content page-columns page-full column-page" id="quarto-document-content">




<div class="quarto-about-solana column-page">
  <div class="about-entity">
    <div class="entity-contents">
      <header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Bayesian Changepoint Detection on Price Histograms</h1>
<p class="subtitle lead">Bayesian decomposition of sales dynamics with NumPyro</p>
</div>
<div>
  <div class="description">
    In-depth data science case studies demonstrating Bayesian methods, time series analysis, changepoint detection, and LLM applications.
  </div>
</div>
<div class="quarto-title-meta column-page">
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">r Sys.Date()</p>
    </div>
  </div>
  </div>
</header> <div class="about-links">
  <a href="https://www.linkedin.com/in/pavel-logacev" class="about-link" rel="" target="">
    <i class="bi bi-linkedin"></i>
     <span class="about-link-text"></span>
  </a>
  <a href="https://github.com/plogacev" class="about-link" rel="" target="">
    <i class="bi bi-github"></i>
     <span class="about-link-text"></span>
  </a>
</div>
      <div class="about-contents"><div id="hero-heading">
<p>I‚Äôm a freelance data scientist specializing in statistical modeling for business decisions ‚Äî particularly in settings where data is messy, experimentation is limited, and off-the-shelf solutions fall short.</p>
<p>My work spans demand modeling, price elasticity estimation, forecasting, and causal inference. I build custom models using Bayesian methods, designed around the structure of your specific problem.</p>
<p>I‚Äôve worked across B2C and B2B contexts, collaborating closely with stakeholders to understand how business processes actually work ‚Äî so models reflect what matters and make the most of available data.</p>
<p><a href="./about" class="about-links">Learn more ‚Üí</a></p>
</div></div>
    </div>
    <img src="assets/images/pavel.png" alt="Pavel Logaƒçev - Freelance Data Scientist" class="about-image
  rounded " style="width: 28em;">
  </div>
</div>




<div id="hero-heading">
<p>I help companies make better decisions through statistical modeling ‚Äî especially when data is limited, messy, or poorly understood.</p>
<p><strong>How I work</strong></p>
<ul>
<li>I take time to understand your business context before modeling</li>
<li>I build interpretable models, not black boxes</li>
<li>I deliver working solutions ‚Äî not just reports</li>
<li>I communicate clearly with technical and non-technical stakeholders</li>
</ul>
<p><a href="./contact.html">Get in touch</a> if you‚Äôd like to work together.</p>
</div>
<div class="grid">
<section id="what-i-do" class="level2 g-col-6">
<h2 data-anchor-id="what-i-do">What I Do</h2>
<ul>
<li>Price elasticity estimation and price optimization</li>
<li>Bayesian methods for sparse data</li>
<li>Demand modeling and forecasting</li>
<li>Causal inference (A/B tests, observational studies)</li>
<li>Custom models tailored to your domain and problem</li>
</ul>
</section>
<section id="background" class="level2 g-col-6">
<h2 data-anchor-id="background">Background</h2>
<p>PhD in Cognitive Science (University of Potsdam). Before freelancing, I worked in academic research and then transitioned to applied data science in industry.</p>
<p>I‚Äôve worked with retailers, distributors, and restaurant chains on problems involving pricing, demand, and forecasting. Most of my work is done through agencies, but I also take on direct engagements.</p>
<p>Based in Berlin. I work with clients across Europe and North America.</p>
<p>I speak English, German, Russian, and a little Turkish.</p>
</section>
</div>
<div class="grid">
<div id="note" class="g-col-5">
<section id="drop-me-a-note" class="level2">
<h2 data-anchor-id="drop-me-a-note">Drop me a note</h2>
<p>If you‚Äôd like to discuss a potential project, collaboration, or have a question about statistical modeling, forecasting, or data science ‚Äî feel free to reach out.</p>
<p>You can also find me on:</p>
</section>
</div>
<!-- source: https://github.com/mccarthy-m-g/tidytales/blob/main/about/index.qmd#L24-L46 -->
<div class="g-col-1">

</div>
<div id="form" class="g-col-6">
<form style="margin-top: -5em;" action="https://formspree.io/f/mwkapgzw" method="POST" accept-charset="utf-8">
<p><label for="full-name">Full Name</label> <input type="text" name="name" id="full-name" class="form-control" placeholder="First and Last" required=""></p>
<p><label for="email-address">Email Address</label> <input type="email" name="_replyto" id="email-address" class="form-control" placeholder="your@email.here" required=""></p>
<label for="message">Message</label>
<textarea rows="6" name="message" id="message" class="form-control" required=""></textarea>
<p><!--
   placeholder="Aenean lacinia bibendum nulla sed consectetur. Vivamus sagittis lacus vel augue laoreet rutrum faucibus dolor auctor. Donec ullamcorper nulla non metus auctor fringilla nullam quis risus."
  --></p>
<button type="submit" class="btn btn-primary mt-4">
Send message
</button>
</form>
</div>
<p>Selected examples of data science work. Details are anonymized to protect client confidentiality.</p>
<p>Detailed case studies with full code and methodology. Each project demonstrates practical applications of Bayesian statistics, time series analysis, and machine learning techniques.</p>
<section id="summary" class="level2">
<h2 data-anchor-id="summary">Summary</h2>
<p>The notebooks in this folder demonstrate multiple implementations of a Bayesian changepoint detection model applied to synthetic sales data, where product prices change over time. The goal is to detect structural changes in pricing regime based on price histograms over time when the pricing of a product undergoes a meaningful change ‚Äî such as list price changes, promotions, or changes in the availability of discounts.</p>
<p>We assume that the distribution of prices for a product on any given day depends on the underlying price regime, which changes infrequently. While the price regime (list price and available discounts) remains stable for extended periods, the daily average price can fluctuate substantially due to varying proportions of discounted sales. Therefore, using the average price within a stable regime as a predictor is likely more informative than using volatile daily average prices.</p>
<p>The model determines pricing regimes based on daily price histograms (i.e., distributions of sold units across different price points). The first implementation, written in Rcpp, uses discrete parameters. The parameter estimation is carried out using a genetic algorithm implementation in R. The second implementation marginalizes out the discrete segmentation parameters and estimates probabilities of specific changepoint locations. Both are designed to serve as a modular component within larger hierarchical models for retail analytics.</p>
</section>
<section id="theoretical-model-assumptions" class="level2">
<h2 data-anchor-id="theoretical-model-assumptions">1. Theoretical Model Assumptions</h2>
<p>[<a href="./model_assumptions.html">Notebook</a>]</p>
</section>
<section id="greedy-changepoint-selection" class="level2">
<h2 data-anchor-id="greedy-changepoint-selection">2. Greedy Changepoint Selection</h2>
<p>[<a href="./greedy_cp_selection.html">Notebook</a>]</p>
</section>
<section id="summary-1" class="level2">
<h2 data-anchor-id="summary-1">Summary</h2>
<p>Demonstrates a two-stage pipeline that uses large language models (LLMs) to elicit reasonable price distributions for consumer products when competitor pricing data is insufficient or historical sales data is sparse. It extracts structured product attributes from free-text titles and descriptions (via GPT-3.5-turbo), then uses GPT-4o to elicit a retail price range (minimum, typical, maximum) based on those attributes and regional context. The elicited price ranges are used to reverse-engineer log-normal distribution parameters, which are validated against actual prices scraped from Mercado Libre. The result is a calibrated, probabilistic estimate of product pricing grounded in LLM-elicited knowledge.</p>
</section>
<section id="implementation-with-chatgpt" class="level2">
<h2 data-anchor-id="implementation-with-chatgpt">1. Implementation with ChatGPT</h2>
<p>üîó [<a href="./price_distribution_elicitation.html">Notebook</a>]</p>
</section>
<section id="summary-2" class="level2">
<h2 data-anchor-id="summary-2">Summary</h2>
<p>Bayesian Hidden Markov Model for detecting stockouts in sales data with no explicit inventory information. A synthetic dataset is generated with steady latent demand and known stockout periods to demonstrate the principle. Realized sales are treated as true demand realizations except during stockouts, which structurally force sales to zero and hide actual demand. The model treats sales as emissions from two hidden states - regular sales and stockout - with state transitions governed by a Markov process. Inference is performed in Stan using MAP estimation and the Viterbi algorithm to recover the most likely stockout periods. The result shows how probabilistic state-switching can uncover unobserved stockouts that distort sales data.</p>
</section>
<section id="simple-hmm" class="level2">
<h2 data-anchor-id="simple-hmm">1. Simple HMM</h2>
<p>üîó [<a href="./stockouts.html">Notebook</a>]</p>
</section>
<section id="summary-3" class="level2">
<h2 data-anchor-id="summary-3">Summary</h2>
<p>Sales data can be somewhat chaotic ‚Äî fluctuating strongly due to market trends, changes in advertising strategy, seasonal cycles, and external shocks. Many analytical methods struggle to disentangle meaningful patterns from noise. The present project explores the potential of a Bayesian time series model to break down variance into distinct components.</p>
<p>We put it to the test using a synthetic sales dataset designed with well-defined patterns: long-term growth, yearly seasonality, weekly variation, and price sensitivity. The model performed remarkably well, accurately identifying key trends while also quantifying uncertainty. The results highlight the power of Bayesian inference in revealing the drivers of sales dynamics, offering businesses a clearer, data-driven perspective and enabling decision-making that fully accounts for the uncertainty in the estimates.</p>
</section>
<section id="synthetic-data-generation" class="level2">
<h2 data-anchor-id="synthetic-data-generation">1. Synthetic Data Generation</h2>
<p>üîó [<a href="./ts_1_synthetic_data.html">Notebook</a>]</p>
</section>
<section id="data-analysis" class="level2">
<h2 data-anchor-id="data-analysis">2. Data Analysis</h2>
<p>üîó[<a href="./ts_2_analysis.html">Notebook</a>]</p>
<p><code>{r message=FALSE, warning=FALSE} library(Rcpp) source("./source/data_generation.r") source("./source/greedy_cp_selection.r") Rcpp::sourceCpp("./source/greedy_cp_selection.cpp")</code></p>
</section>
<section id="summary-4" class="level2">
<h2 data-anchor-id="summary-4">Summary</h2>
<p>This notebook demonstrates a Bayesian changepoint detection algorithm for histogram-valued time series. It is based on a greedy search tailored for transactional price data with varying pricing regimes.</p>
<ul>
<li>Each day‚Äôs price distribution is modeled via discretized histograms.</li>
<li>The changepoint configuration is selected via greedy MAP estimation.</li>
<li>In the future, parameters may be obtained by means of sampling instead of greedy search. (For instance, using RcppSMC or a custom sampler, e.g., MH).</li>
</ul>
</section>
<section id="modeling-approach" class="level2">
<h2 data-anchor-id="modeling-approach">Modeling Approach</h2>
<p>We model the price distribution of a product as a histogram over discrete price points, because in B2C scenarios, only a few specifc prices are available at any given time. Some customer groups may be offered a discount, while most purchase at the list price. Modeling daily means or medians may lose the multimodal structure that matters most for detecting pricing regimes. Histogram-valued preserve the full distributional shape, making it possible to detect subtle regime shifts such as list price changes or availability of discounts. The method is useful for detecting changes in pricing regimes, such as list price changes, promotions, or changes in the availability of discounts.</p>
<p>Each day is represented by a histogram over discrete price points. The time series is transformed into a histogram-valued sequence, represented as a matrix of counts. We assume that pricing follows distinct <em>pricing regimes</em>, each associated with a different price distribution. Changes in pricing regime occur when the pricing of a product undergoes a meaningful change ‚Äî such as list price changes, promotions, or changes in the availability of discounts. Changepoints are defined as time indices where the underlying price distribution regime changes, leading to a change in relative frequency of price points.</p>
<section id="data-format" class="level3">
<h3 data-anchor-id="data-format">Data Format</h3>
<p>The synthetic data used in this notebook simulates 800 days of pricing activity, segmented into 10 regimes characterized by different list prices, discounts, and discount availability</p>
<pre class="{r}"><code>set.seed(123)

segments &lt;- data.frame(
             start_day = c(1,  90, 250, 300, 400, 500, 550, 600, 700, 750),
            list_price = c(5,    6,   6,   6,   6, 5.5, 5.5, 5.5, 7, 7),
        discount_price = c(4,    4,   5,   5,   5, 4.5, 4.5, 4.5, 2, 2),
   discount_percentage = c(.25, .1,  .1, .25,  .5, .01, .03, .15,.3, .4)
)

n_days &lt;- 800
lambda_qty &lt;- 20
df &lt;- generate_transaction_prices(segments, n_days, lambda_qty, seed = 123)
hist &lt;- compute_price_histogram(df)
actual_changepoints &lt;- segments$start_day[-1]-0.5

knitr::kable(segments, caption = "Price Regimes Overview")</code></pre>
<p>The plot below shows the synthetic data set, with the actual changepoints marked with dashed vertical lines. This is the dataset we‚Äôll use to test the segmentation algorithm.</p>
<p>```{r fig.height=3, fig.width=10} p_price &lt;- hist$df %&gt;% rename(quantity = qty) %&gt;% filter(quantity &gt; 0) %&gt;% ggplot(aes(day, price)) + geom_point(aes(size=quantity, alpha = quantity)) + geom_vline( data = data.frame(x = actual_changepoints, changepoint = ‚Äúactual‚Äù), aes(xintercept = x, color = changepoint), linetype = ‚Äúdashed‚Äù) + theme_bw() + theme(legend.position = ‚Äútop‚Äù)</p>
<p>print(p_price)</p>
<pre><code>
### Model Structure

#### Segmentation

We define a segmentation of a histogram-valued time series $h$ of length $T$ as a vector $z \in \{0, 1\}^{T-1}$, where $z_t=1$ indicates a changepoint between indices $t$ and $t+1$, and $0$ indicates its absence. From the index vector $z$, we can derive a segmentation in the form of $\mathcal{S}(z)$, i.e., a set of all segment intervals $[t_1, t_2]$.

The model is intended to select a segmentation $z$ that best balances *(i)* goodness-of-fit (how well the empirical histograms are explained within segments) with *(ii)* model simplicity (how many changepoints are included). The balance is governed by the regularizing parameter $\lambda$, which is selected by optimizing the posterior likelihood over it.

The posterior over a changepoint configurations $z$ is assumed to be:

$$
p(z \mid \mathbf{n}, \lambda) \propto p(\mathbf{n} \mid z) \cdot p(z) \cdot p(\lambda)
$$

### Likelihood

The data likelihood is computed as the product of likelihoods of the segments defined by the segmentation $\mathcal{S}(z)$, where $\mathbf{n}_{[t_1, t_2]}$ stands for the histogram over the interval $[t_1, t_2]$.

$$
p(\mathbf{n} \mid z) = \prod_{(t_1, t_2) \in \mathcal{S}(z)} p(\mathbf{n}_{[t_1, t_2]})\text{,}
$$

```{=html}
&lt;!--
$$
\mathbf{n_{[t_1, t_2]}} = \sum_{t = t_1}^{t_2} \mathbf{h}_t
$$
--&gt;</code></pre>
<p>The likelihood of a segment <span class="math inline">\(\mathbf{n}_{[t_1, t_2]}\)</span> is set to it (regularized) maximum likelihood estimate ‚Ä¶ (explain more) ‚Ä¶, where <span class="math inline">\(\hat{p}_i\)</span> is the (regularized) maximum likelihood estimate of the relative frequencies of the different price points. This corresponds to using the <strong>maximum likelihood estimate</strong> of the multinomial probabilities within each segment. Although technically this is not fully Bayesian (since we‚Äôre not integrating over latent parameters), it can be viewed as an empirical Bayes approximation.</p>
<p><span class="math display">\[
p(\mathbf{n}_{[t_1, t_2]}) = \sum_{i=1}^{K} (\hat{p}_i)^{n_i}
\]</span></p>
<p>In computing <span class="math inline">\(\hat{p}_i\)</span>, we smooth each bin count with a small constant <span class="math inline">\(\epsilon\)</span> to prevent division by zero.</p>
<p><span class="math display">\[
\hat{p}_i = \frac{n_i + \epsilon}{\sum_j (n_j + \epsilon)}
\]</span></p>
</section>
<section id="prior" class="level3">
<h3 data-anchor-id="prior">Prior</h3>
<p>We place a Bernoulli prior on each potential changepoint, to penalize excessive complexity: small <span class="math inline">\(\lambda\)</span> values encourage fewer changepoints, favoring parsimony. In consequence, the model selects the segmentation <span class="math inline">\(z\)</span> that best balances goodness-of-fit (how well the empirical histograms are explained within segments) with model simplicity (how many changepoints are included). The balance is governed by <span class="math inline">\(\lambda\)</span>.</p>
<p><span class="math display">\[
z_t \sim \text{Bernoulli}(\lambda)
\]</span></p>
</section>
</section>
<section id="estimation" class="level2">
<h2 data-anchor-id="estimation">Estimation</h2>
<p>To estimate the changepoint configuration <span class="math inline">\(z\)</span>, we use a greedy forward search:</p>
<ol type="1">
<li>Start with no changepoints.</li>
<li>Iteratively add the changepoint that most increases the penalized posterior.</li>
<li>Stop when no further improvement is possible.</li>
</ol>
<p>This process is repeated for different values of <span class="math inline">\(\lambda\)</span>, and the <span class="math inline">\(\lambda\)</span> value that maximizes the resulting posterior is selected using one-dimensional optimization (<code>optimize()</code> in R).</p>
</section>
<section id="implementation" class="level2">
<h2 data-anchor-id="implementation">Implementation</h2>
<p>This project implements a greedy changepoint detection algorithm for time series of price histograms. The codebase consists of three components:</p>
<ul>
<li>A data generator that simulates daily transaction-level price data under piecewise constant pricing regimes (<code>generate_transaction_prices()</code>).</li>
<li>A transformation step that maps transactional data into a histogram matrix (<code>compute_price_histogram()</code>).</li>
<li>A C++ backend that performs fast log-likelihood evaluation and greedy changepoint selection via Rcpp.</li>
</ul>
</section>
<section id="changepoint-detection-results" class="level2">
<h2 data-anchor-id="changepoint-detection-results">Changepoint Detection Results</h2>
<p>In the present example, the algorithm detects the same number changepoints, and the estimates ones, are largely fairly close to the simulated ones. A formal evaluation is pending. It stands to reason that the accuracy of changepoint identification will depend on the similarity between adjacent segments, as well as segment length.</p>
<pre class="{r }"><code>opt_res &lt;- locate_optimal_changepoints( hist$histogram, max_lambda = 0.3 )
detected_changepoints &lt;- which(opt_res$changepoints) - 0.5

knitr::kable(t(actual_changepoints), caption = "Original Changepoints")
knitr::kable(t(detected_changepoints), caption = "Detected Changepoints")
</code></pre>
<p>The plot below illustrates the results vis a vis the simulation assumptions.</p>
<p><code>{r thumbnail-image, fig.height=3, fig.width=10} #| label: thumbnail-image p_price +       geom_vline( data = data.frame(x = detected_changepoints, changepoint = "detected"),                   aes(xintercept = x, color = changepoint), linetype = "dashed") +       scale_color_manual(name = "changepoint", values = c("detected" = "blue", "actual" = "red"),                         guide = guide_legend(override.aes = list( linetype = "solid", size = 1))                         )</code></p>
</section>
<section id="limitations" class="level2">
<h2 data-anchor-id="limitations">Limitations</h2>
<ul>
<li>The algorithm is designed to detect even small changes in average price if they are sufficiently frequent.</li>
<li>In the present version, it cannot deal with days with no sales, and may possibly identify them as a new pricing regime, thus zero-sales days have to be excluded before running it.</li>
<li>The algorithm is not designed to deal with overlapping price regimes.</li>
</ul>
</section>
<section id="repository" class="level2">
<h2 data-anchor-id="repository">Repository</h2>
<p>All source code is available here:<br>
üëâ <a href="https://github.com/plogacev/case_studies/tree/main/pricedist_changepoints" class="uri">https://github.com/plogacev/case_studies/tree/main/pricedist_changepoints</a></p>
<pre><code class="language-cpp">
double log1m_exp(double x)
{
if (x &gt;= 0.0) stop("log1m_exp is undefined for x &gt;= 0");
...
}
</code></pre>
</section>
<section id="scope" class="level2">
<h2 data-anchor-id="scope">Scope</h2>
<p><em>[This is work in progress.]</em></p>
<p>All model implementations in this repo are designed to detect change points in pricing time series data. All models are based on a set of assumptions outlined below: In brief, we will assume that the relative frequency of specific prices for a product on a given day depends on the underlying price regime, which is associated with a specific distribution of prices, and changes rather infrequently. The models in this repo are all designed to detect structural changes in pricing regimes based on daily price histograms. Changepoints occur when the pricing of a product undergoes a meaningful change ‚Äî such as list price changes, promotions, or changes in the availability of discounts.</p>
<p>This document outlines the general model assumptions and logic. While none of the actual implementations in this repo actually implement all of them, all models work with some of the assumptions outlined here.</p>
</section>
<section id="theoretical-generative-model" class="level2">
<h2 data-anchor-id="theoretical-generative-model">Theoretical Generative Model</h2>
<p>We model the daily distribution of purchase prices for a product as dependent on the current latent price regime. Within each regime, there is assumed to be one list price, and one or multiple discounts, at which a product can be purchased. Discounts may have different amounts of availability: for instance, only 2% of customers may be eligible for a 10% discount, while only 1% of customers may be eligible for a 20% discount. Price regimes change occasionally. This can be due to changes of the list price, promotions, changes in the magnitude or availability of discounts, or multiple factors.</p>
<p>We assume that each day belongs to a specific pricing regime. At end of the day <span class="math inline">\(t\)</span>, the regime either changes (with probability <span class="math inline">\(\rho_t\)</span>) or remains the same (with probability <span class="math inline">\(1 - \rho_t\)</span>). Each regime is characterized by a distribution over prices. We assume that it follows a multinomial distribution, such that the distribution of prices in pricing regime <span class="math inline">\(k\)</span> follows <span class="math inline">\(\text{Multinomial}(\tau_k)\)</span>.</p>
<p>We encode a segmentation of a price time series of length <span class="math inline">\(T\)</span> using a changepoint indicator vector <span class="math inline">\(z\)</span> of length <span class="math inline">\(T-1\)</span>, where <span class="math inline">\(z_t=1\)</span> indicates a changepoint between time <span class="math inline">\(t\)</span> and <span class="math inline">\(t+1\)</span>, and <span class="math inline">\(z_t=0\)</span> indicates the absence of a changepoint. As a result, each indicator vector defines a set of <span class="math inline">\(K\)</span> segments, where <span class="math inline">\(t_1^{(k)}\)</span> and <span class="math inline">\(t_2^{(k)}\)</span> are the start and end points of segment <span class="math inline">\(k\)</span>: <span class="math display">\[
  [t_1^{(1)},\, t_2^{(1)}], [t_1^{(2)},\, t_2^{(2)}],\quad \dots,\quad [t_1^{(K)},\, t_2^{(K)}]
\]</span> When the pricing regime changes, it needs to change <em>significantly</em>. Thus, we specify a prior <span class="math inline">\(\theta\)</span> over the difference between two adjacent price regime distributions, where the actual difference may be specified in any number ways, including a difference between means, the Wasserstein distance, etc.</p>
<p>The complete posterior distribution for the changepoint detection model combines the likelihood of the observed data with the prior distributions over the changepoint configuration and the regime differences. The posterior is given by:</p>
<p><span class="math display">\[
p(z, \theta, \tau \mid y_{1:T})
\propto
p(y_{1:T} \mid z, \theta, \tau)
\cdot
p(z, \theta, \tau)\text{, where }
\]</span></p>
<p><span class="math display">\[
p(z, \theta, \tau) =
p(z)
\cdot
p(\theta)
\cdot
p(\tau)\text{, and where }
\]</span></p>
<ul>
<li><span class="math inline">\(p(y_{1:T} \mid z, \theta, \tau)\)</span> is the likelihood of the observed data given the changepoint configuration <span class="math inline">\(z\)</span>, the changepoint prior <span class="math inline">\(\theta\)</span>, and the regime parameters <span class="math inline">\(\tau\)</span>.</li>
<li><span class="math inline">\(p(z)\)</span> is the prior probability of the changepoint configuration, modeled as a Bernoulli process with changepoint probability <span class="math inline">\(\rho\)</span>.</li>
<li><span class="math inline">\(p(\theta)\)</span> is the prior distribution over the magnitude of the price regime change, specified based on domain knowledge.</li>
<li><span class="math inline">\(p(\tau)\)</span> is the prior distribution over the regime parameters <span class="math inline">\(\tau\)</span>, which incorporates the belief about the differences between successive regimes.</li>
</ul>
<p>It follows from the structure of the model that likelihood of <span class="math inline">\(y_{1:T}\)</span> is as below.</p>
<p><span class="math display">\[
  p(y_{1:T} \mid z, \theta, \tau) = \prod_{k=1}^{K} \prod_{t=t_1^{(k)}}^{t_2^{(k)}} \text{Multinomial}(y_t \mid \tau_k)
\]</span></p>
<p>The prior probability <span class="math inline">\(p(z)\)</span> of a changepoint configuration <span class="math inline">\(z\)</span> can be modeled using a Bernoulli process with a changepoint probability <span class="math inline">\(\rho\)</span>. Assuming each <span class="math inline">\(z_t\)</span> is an independent Bernoulli random variable, the prior can be expressed as below, where <span class="math inline">\(\rho\)</span> is the probability of a changepoint occurring between any two consecutive time points.</p>
<!-- p(z) = \prod_{t=1}^{T-1} \rho^{z_t} (1-\rho)^{1-z_t} -->
<p><span class="math display">\[
  z \sim Bernoulli(\rho)
\]</span></p>
<p>We further incorporate a prior for the differences between successive <span class="math inline">\(\tau_k\)</span> to capture the belief that changes in pricing regimes are typically abrupt rather than gradual, and that two adjacent pricing regimes need to be substantially different in order to justify positing a regime switch. In other words, it penalizes small differences between any two adjacent pricing regimes. One example specification is as below, where <span class="math inline">\(\delta\)</span> is any kind of distance function calculating <em>absolute</em> differences between two distributions.</p>
<p><span class="math display">\[
  \delta(\tau_k, \tau_{k+1}) \sim Normal( \theta_{\mu}, \theta_{\sigma} )
\]</span></p>
</section>
</div>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/plogacev\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>