{
  "hash": "e1ba1ffb9c15b3ddbaec58613e7053da",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Price Distribution Elicitation from an LLM\"\nsubtitle: \"Using GPT-4o to estimate plausible price ranges for products\"\nauthor: \"Pavel Logaƒçev\"\ndate: 2025-07-10\nimage: images/thumbnail.png\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-tools: true\n    df-print: paged\nengine: knitr\neditor: visual\nexecute:\n  eval: false\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(reticulate)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport os\nimport polars as pl\nimport re\nimport ast\nfrom tqdm import tqdm\nimport math\nimport itertools\nimport openai\nimport pickle\n\nfrom dotenv import load_dotenv\n\nfrom openai import OpenAI\nfrom joblib import Memory\n\n# \ntmp = load_dotenv()\n\n# save the results from the LLM model to a cache\nmemory_summary = Memory(location=\"cache_summary\", verbose=0)\nmemory_pricing = Memory(location=\"cache_pricing\", verbose=0)\n```\n:::\n\n\n\n## Summary\n\nDemonstrates a two-stage pipeline that uses large language models (LLMs) to elicit reasonable price distributions for consumer products when competitor pricing data is insufficient or historical sales data is sparse. It extracts structured product attributes from free-text titles and descriptions (via GPT-3.5-turbo), then uses GPT-4o to elicit a retail price range (minimum, typical, maximum) based on those attributes and regional context. The elicited price ranges are used to reverse-engineer log-normal distribution parameters, which are validated against actual prices scraped from Mercado Libre. The result is a calibrated, probabilistic estimate of product pricing grounded in LLM-elicited knowledge.\n\n## Motivation and Approach\n\nWhen pricing a new product for the first time, or re-evaluating an existing product's pricing, pricing analysts are often flying blind. In many cases, there is no information about competitor pricing, limited or no sales history, and little variability in past price points. As a result, prices can‚Äôt be based on competitive benchmarks or estimated elasticities. Yet a price still needs to be set.\n\nIn these situations, the goal is not precision: it is to make a well-reasoned initial decision. The price should be high enough to protect margin, low enough to be competitive, and aligned with how a reasonably informed customer would perceive the product: what it does, what it's made of, who it's for, and how the brand signals quality or positioning.\n\nTo support this task, the notebook demonstrates a two-stage pipeline using large language models (LLMs) for eliciting reasonable price ranges. The method is applied to consumer product data from Mercado Libre sourced from [here](https://github.com/pjstoc2/mercadolibre_analysis):\n\n1.  Product Attribute Extraction GPT-3.5-turbo is used to extract a structured set of pricing-relevant attributes ‚Äî such as product type, components, materials, intended use, and product tier ‚Äî from unstructured titles and descriptions. The output is a standardized schema of factual product properties.\n\n2.  Price Range Elicitation GPT-4o is then used on attributes to elicit a plausible retail price range ‚Äî minimum, typical, and maximum ‚Äî conditioned on regional market context (e.g., country, currency, and year).\n\nThe two-step approach has several advantages over one-shot elicitation:\n\n1.  Explicit control over inputs: By decoupling attribute extraction from price judgment, we can precisely define which aspects of the product are considered ‚Äî such as function, materials, target user, or technical features ‚Äî rather than letting the model base its pricing on irrelevant or misleading text. This reduces hallucinations and improves consistency.\n\n2.  Cost efficiency: Structured product summaries can be generated using a much smaller model and inexpensive model than the one used for eliciting price points, such as a local *mt5-small* or *GPT-3.5-turbo*, with only the pricing step, which benefits from broader and more recent market knowledge, being handled by GPT-4o. This separation helps control token usage and reduces overall API costs.\n\n3.  Transparency and auditability: Having an explicit intermediate representation allows analysts to inspect what the model \"saw\" before making a pricing judgment. This makes the process easier to debug, validate, or even override with human input if needed.\n\nBoth stages are implemented with batched processing, caching (joblib.Memory), and fallback logic to ensure reliability and scalability. The resulting price ranges can be used to support pricing diagnostics, detect potential over- or underpricing, and provide a structured starting point for analyst review.\n\n### Data\n\nThe dataset (sourced from [here](https://github.com/pjstoc2/mercadolibre_analysis)) contains $5,859$ product listings from *Mercado Libre*, a major Latin American e-commerce platform. The data was likely obtained via web scraping. The presence of both original and discounted prices suggests that pricing metadata was parsed directly from the listing structure, possibly through structured HTML extraction.\n\nIn the present notebook, we use the following columns:\n\n-   `product_title`: a free-text product title from the listing (in Spanish)\n-   `product_description`: a potentially marketing description (in Spanish)\n-   `price_usd`: the listed retail price, converted to USD\n-   `price_discounted_usd`: the discounted price (if applicable), also converted to USD\n-   `product_url`: a direct link to the product listing (mainly used for debugging)\n-   `product_id`: a synthetic ID assigned during preprocessing (mainly used for debugging)\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nproducts = pl.read_csv(\"./data/mercado_libre_products_cleaned.csv\")\nproducts = (products\n            .rename({'Product': 'product_title', 'Description': 'product_description',\n                      'Product URL': 'product_url',\n                      'MXN': 'price_mxn', 'USD': 'price_usd', \n                      'Sale Price USD': 'price_discounted_usd'})\n            .with_columns( pl.arange(0, products.height).alias('product_id') )\n            .select([ 'product_id', 'product_title', 'product_description', 'price_usd', 'price_discounted_usd', 'product_url'])\n           )\n```\n:::\n\n\n\n-   Let's take a look at the data frame with the product information.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npy$products$to_pandas()\n```\n:::\n\n\n\n-   Next, we connect to OpenAI.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nclient = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n```\n:::\n\n\n\n### Product Attribute Extraction\n\n-   Below is the prompt that serves to extract the pricing-related features from the product title and product description. In principle, the product images can be included as well.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprompt_template_product_properties = \"\"\"\nYou are a product analyst.\n\nExtract pricing-relevant attributes from each of the following products.\n\nFocus exclusively on the **actual nature and use** of the product ‚Äî its type, components, materials, and intended use ‚Äî as well as the intended target group.  \nDo not be influenced by stylistic choices, promotional language, or verbosity in the original title or description.\n\nFor each product, extract the following information:\n- Brand ‚Äì if applicable\n- Core Product Name without any unnecessary qualifications, if one is available; in English if internationally known\n- Product Type ‚Äì general category or function of the item\n- Key Components ‚Äì any major physical or electronic subcomponents (e.g., power adapter, filter unit)\n- Distinguishing Product Features ‚Äì physical or functional traits not found in all comparable products (e.g., \"72h battery life\", \"IP68 water resistance\", \"remote control\", \"8-core CPU\")\n- Variant Features ‚Äì options that vary across listings or versions, such as size, color, voltage, memory, etc.\n- Functional Tier ‚Äì classify the product as \"budget\", \"standard\", or \"premium\" based on: objective technical features, material quality, and positioning within the brand‚Äôs lineup or market segment.\n    - Exclude marketing phrasing and minor stylistic differences (e.g., LED clock, color options, decorative packaging).\n    - A product is premium only if it clearly surpasses alternatives in core functionality, quality, and typical price level.\n- Materials ‚Äì main materials used (e.g., plastic, steel, leather)\n- Intended Use ‚Äì main use case (e.g., \"home cleaning\", \"child transport\", \"audio playback\")\n- Target User ‚Äì intended end-user (e.g., \"toddlers\", \"pet owners\", \"DIY hobbyists\")\n- Quantity or Unit Size ‚Äì volume, weight, or unit count (in metric units if applicable)\n- Year of Make ‚Äì if known or can be inferred\n- Regulatory Certifications or Standards ‚Äì if applicable (e.g., CE, FDA, NOM)\n- Likely Group Marketed To ‚Äì broad audience the product seems designed for (e.g., \"fitness enthusiasts\", \"tech-savvy users\")\n- Likely Income Bracket ‚Äì infer \"low\", \"middle\", or \"high\" based on the nature of the product and its expected price range, not on superficial style\n\n\nProducts:\n{product_blocks}\n\nInstructions:\nReturn a syntactically valid Python list of dicts. Each dict must correspond to one product, and must include the following fields in this exact order:\n\n`product_id, brand, product_name, product_type, components, product_features, variant_features, functional_tier, materials, intended_use, target_user, quantity, year_make, regulatory_certifications, marketed_to, marketed_to_income`\n\n- When a property is unknown or unclear, and an educated guess is not possible, return `'-'` for that field\n- Do **not** use vague summaries or marketing phrasing ‚Äî extract or infer concrete factual content only\n- Use **European metrics** for quantity/unit size (e.g., ml, cm, g); convert if necessary\n- Do not include explanations, markdown, or formatting beyond the list of dicts\n\"\"\".strip()\n```\n:::\n\n\n\n-   Here, we define the the logic of the product feature extraction.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef make_product_blocks(product_list):\n    blocks = []\n    for i, product in enumerate(product_list, 1):\n        blocks.append(f\"\"\"Product {i}:\n                          <ID>\n                          {product['product_id']}\n                          </ID>\n                          <TITLE>\n                          {product['product_title']}\n                          </TITLE>\n                          <DESCRIPTION>\n                          {product['product_description']}\n                          </DESCRIPTION>\n                      \"\"\")\n    return \"\\n\\n\".join(blocks).strip()\n\n@memory_summary.cache(ignore=[\"client\"])\ndef summarize_product_descriptions_batch(client, product_list):\n        \"\"\" \"\"\"\n        product_blocks = make_product_blocks(product_list)\n        \n        prompt = prompt_template_product_properties.format(\n            product_blocks=product_blocks\n        )\n\n        try:\n          response = client.chat.completions.create(\n              model=\"gpt-3.5-turbo\",\n              messages=[{\"role\": \"user\", \"content\": prompt}],\n              temperature=0,\n          )\n          \n          reply = response.choices[0].message.content\n          reply = re.sub(r\"^```(?:python)?\\s*|\\s*```$\", \"\", reply.strip(), flags=re.IGNORECASE)\n          reply = ast.literal_eval(reply)\n\n        except:\n          if batch_size == 1:\n              raise\n          new_batch_size = math.floor(batch_size/2)\n          #print(f\"new batch size: {new_batch_size}\")\n          #if \"maximum context length\" in str(e):\n          return summarize_product_descriptions(client, product_list, batch_size=new_batch_size)\n        \n        # to-do: make sure all products were returned, and re-request the missing ones if any were missing\n\n        return reply\n\n\n@memory_summary.cache(ignore=[\"client\"])\ndef summarize_product_descriptions(client, product_list, batch_size=10):\n    \"\"\" \"\"\"\n    num_batches = math.ceil(len(product_list) / batch_size)\n    product_list_it = iter(product_list)\n    \n    results = []\n    for _ in tqdm(range(num_batches), desc=\"Retrieving price ranges\"):\n        product_batch = list(itertools.islice(product_list_it, batch_size))\n        result_batch = summarize_product_descriptions_batch(client, product_batch)\n        results.extend(result_batch)\n\n    return results\n```\n:::\n\n\n\n-   Let's extract pricing-related product attributes now, caching them during and after retrieval.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nproduct_list = products[['product_id', 'product_title', 'product_description']].to_dicts()\n\nfname_product_summaries = \"product_summaries_chatgtp35_turbo.pkl\"\nif not os.path.exists(fname_product_summaries):\n    product_summaries = summarize_product_descriptions(client, product_list, batch_size = 10)\n    \n    with open(fname_product_summaries, \"wb\") as f:\n      pickle.dump(product_summaries, f)\n      \nelse:\n    with open(fname_product_summaries, \"rb\") as f:\n        product_summaries = pickle.load(f)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# Coerce lists to strings for compatibility\nproduct_summaries_uniform = [\n    {k: \", \".join(v) if isinstance(v, list) else v for k, v in row.items()}\n    for row in product_summaries\n]\n\nproduct_summaries_uniform_df = pl.DataFrame(product_summaries_uniform)\n```\n:::\n\n\n\n-   Let's take a look at the results of this feature extraction.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npy$product_summaries_uniform_df$to_pandas()\n```\n:::\n\n\n\n### Price Range Elicitation\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# to-do: do mention that we're looking for *list* prices, and not any kind of discounted or promotional prices -- or maybe elicit both types of prices (sometimes the 'discounted price' is the actual price)\nprompt_template_price_range = \"\"\"\nYou are a pricing assistant.\n\nEstimate the typical **online retail** price range for each of the following products, based on publicly available prices in {region}, as close to the year {year} as possible. Prioritize prices from local online platforms and regional e-commerce sites. If local data is scarce, use prices from the most **geographically or economically comparable regions** for which prices are available.\n- Prioritize sources with high traffic and strong market influence (e.g., Amazon, local online supermarkets, major regional e-commerce platforms).\n- Reflect everyday consumer pricing ‚Äî exclude promotional or bulk prices.\n\nAll prices must be reported in **{currency}**. If source prices are in a different currency, adjust to {currency} using appropriate historical exchange rates and contextual knowledge.\n\nFocus exclusively on the **actual nature and use** of the product, and the target group ‚Äî its type, components, materials, and intended use.\n- Ignore stylistic or marketing choices in the title or description (e.g., exaggerated adjectives, description length, or promotional phrasing).\n- Prioritize functional and categorical cues, such as:\n  - What is the product?\n  - What is it made of?\n  - Who is it for (e.g. child vs. adult, consumer vs. professional)?\n  - How is it typically used?\n\nFor each product, estimate:\n- The **lowest plausible price** ‚Äî the lowest price a typical retailer might charge for this item, excluding outliers or defective goods.\n- The **highest plausible price** ‚Äî the upper bound of reasonable retail pricing, excluding rare luxury versions or bundles.\n- The **most typical price** ‚Äî the price point at which the product is most commonly sold (median or mode).\n\nProducts:\n{product_summary}\n\nInstructions:\nReturn a syntacticly valid python list of lists, each in the following format:\n[product_id, lowest_price, highest_price, typical_price]\n\nDo not include explanations, citations, or formatting beyond this structure.\n\"\"\".strip()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n@memory_pricing.cache(ignore=[\"client\"])\ndef retrieve_price_ranges_batch(client, product_summary, currency, year, region):\n    \"\"\" \"\"\"\n    prompt = prompt_template_price_range.format(\n        product_summary=pprint.pformat(product_summary),\n        currency=currency,\n        year=year,\n        region=region,\n    )\n    #prompt = re.sub(r'\\s+', ' ', prompt)\n    #print(prompt)\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0,\n    )\n    \n    reply = response.choices[0].message.content\n    reply = re.sub(r\"^```(?:python)?\\s*|\\s*```$\", \"\", reply.strip(), flags=re.IGNORECASE)\n    estimates = ast.literal_eval(reply)\n    \n    results = []\n    for est in estimates:\n        cur_result = { 'product_id':  est[0], 'lower': est[1], 'upper': est[2], 'typical': est[3] }\n        results.append( cur_result )\n    \n    # to-do: make sure all products were returned, and re-request the missing ones if any were missing\n    \n    return results\n\n@memory_pricing.cache(ignore=[\"client\"])\ndef retrieve_price_ranges(client, product_summary, currency, year, region, batch_size=10):\n    \"\"\" \"\"\"\n    num_batches = math.ceil(len(product_summary) / batch_size)\n    product_list_it = iter(product_summary)\n    \n    results = []\n    for _ in tqdm(range(num_batches), desc=\"Retrieving price ranges\"):\n        product_batch = list(itertools.islice(product_list_it, batch_size))\n        result_batch = retrieve_price_ranges_batch(client, product_batch, currency, year, region)\n        results.extend(result_batch)\n\n    return results\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ncurrency = \"USD\"\nyear = 2025\nregion = \"Mexico\"\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfname_estimates = \"estimates_chatgtp4o.pkl\"\n\nif not os.path.exists(fname_estimates):\n    estimates = retrieve_price_ranges(client, product_summaries_uniform, currency, year, region, batch_size = 15)\n    \n    with open(fname_estimates, \"wb\") as f:\n      pickle.dump(estimates, f)\n      \nelse:\n    with open(fname_estimates, \"rb\") as f:\n        estimates = pickle.load(f)\n```\n:::\n\n\n\n## Evaluation\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pickle\n\nwith open(\"product_summaries_chatgtp35_turbo.pkl\", \"rb\") as f:\n    product_summaries = pickle.load(f)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nestimates = pl.DataFrame( estimates )\nestimates = estimates.with_columns( pl.col(\"product_id\").cast(pl.Int128) ) \nproduct_prices = products.join( estimates, how = \"left\", on = \"product_id\" )\nproduct_prices_pd = product_prices.to_pandas()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nproduct_prices <- py$product_prices$to_pandas() %>% filter(!is.na(typical))\n```\n:::\n\n\n\n### Accuracy on List Prices\n\n-   The plot below shows the actual product list prices in USD (x-axis), along with the elicited prices (y-axis). Both axes are on the log-scale. The vertical bars correspond to price range. Even though there are significant deviations, we can see that the model produces price estimates close to the observed list price.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nproduct_prices %>% filter(!is.na(typical)) %>%\n  ggplot(aes(x = price_usd, y = typical)) +\n  geom_point(alpha=0.3) +\n  geom_errorbar(aes(ymin=lower, ymax=upper), alpha=0.3, width=0) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"red\") +\n  #scale_x_continuous(limits = c(0, 4000)) + scale_y_continuous(limits = c(0, 4000)) +\n  theme_bw() +\n  scale_x_log10(labels = label_dollar(prefix = \"$\", accuracy = 1)) +\n  scale_y_log10(labels = label_dollar(prefix = \"$\", accuracy = 1)) +\n  xlab(\"Actual list price in USD (log-scale)\") +\n  ylab(\"Elicited price in USD (log-scale)\")\n```\n:::\n\n\n\n### Accuracy on Discounted Prices\n\n-   This plot shows the discounted prices in USD (x-axis), along with the elicited prices (y-axis). This plot shows that elicited prices tend to be higher than observed discounted prices.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nproduct_prices %>% filter(!is.na(typical)) %>% \n  ggplot(aes(x = price_discounted_usd, y = typical)) +\n  geom_point(alpha=0.3) +\n  geom_errorbar(aes(ymin=lower, ymax=upper), alpha=0.3, width=0) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"red\") +\n  #scale_x_continuous(limits = c(0, 4000)) + scale_y_continuous(limits = c(0, 4000)) +\n  theme_bw() +\n  scale_x_log10(labels = label_dollar(prefix = \"$\", accuracy = 1)) + \n  scale_y_log10(labels = label_dollar(prefix = \"$\", accuracy = 1)) +\n  xlab(\"Actual discounted price in USD (log-scale)\") +\n  ylab(\"Elicited price in USD (log-scale)\")\n```\n:::\n\n\n\n## Price Distributions\n\nThe elicited price range tends to overestimate actual prices more often than it underestimates them. This is not particularly surprising if we assume that the distribution of market prices for a given product is right-skewed, as is the case with a log-normal distribution.\n\nTo reason more clearly about how these price estimates come about, we adopt a stylized model of the generative process:\n\nFor each product type $i$, the LLM is exposed during training to a sample of $k_i$ observed prices.\n\nIt returns:\n\n-   the minimum of this sample as the lower bound,\n\n-   the maximum as the upper bound, and\n\n-   a typical price that likely corresponds to the median or mode of the sample (theoretically, the mode would be most defensible as a \"typical\" price).\n\nOf course, this model is a deliberate oversimplification. In practice, most products are not represented verbatim in the training data. Instead, the LLM likely draws on similar products and generalizes across categories. But even so, this toy model helps clarify what kind of information the LLM is plausibly encoding and returning ‚Äî namely, some noisy abstraction over a finite sample of real-world prices with unknown size.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nproduct_prices %>% summarize(\n  perc_list_price_lower = mean(price_usd < lower),\n  perc_list_price_higher = mean(price_usd > upper) \n```\n:::\n\n\n\n### Simple Log-Normal Model\n\n-   The goal is to use the LLM-generated estimates to infer a plausible price distribution for each product.\n-   Ideally, this would involve modeling the generative process explicitly‚Äîtreating the elicited range and typical price as functions of latent price distributions, and marginalizing over unknown parameters such as the sample size and distributional shape.\n-   In practice, however, we take a simpler approach: we calibrate the parameters of a log-normal distribution such that the observed proportions of actual prices falling below or above the elicited range align with the expected coverage probabilities. Given our above-stated assumptions, we can reverse-engineer the values of the log-normal parameters $\\mu_i$, $\\sigma_i$ for each product $i$, using the relationship below. Solving these equations gives estimates of $\\mu$ and $\\sigma$ for each product.\n\n$$ log(\\text{lower}) = \\mu + z_{0.3} \\cdot \\sigma $$ $$ log(\\text{upper}) = \\mu + z_{0.8} \\cdot \\sigma $$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define z-scores for assumed quantile boundaries of the elicited range\nz_lower <- qnorm(0.3)\nz_upper <- qnorm(0.8)\n\n# Calibrate log-normal parameters assuming lower and upper are 30% and 80% quantiles\nproduct_prices <- \n  py$product_prices_pd %>%\n  filter(!is.na(lower) & !is.na(upper) & !is.na(price_usd)) %>%\n  mutate(\n    p1_log_sigma = (log(upper) - log(lower)) / (z_upper - z_lower),\n    p1_log_mu = log(lower) - p1_log_sigma * z_lower\n  )\n```\n:::\n\n\n\nWe then validate this calibration by checking how well the empirical price data agrees with the implied distribution. Specifically, we:\n\n1.  Use the calibrated $\\mu$ and $\\sigma$ to compute a range of quantiles.\n\n2.  For each theoretical quantile, we calculate the proportion of real prices that fall under it.\n\n3.  We compare these empirical proportions to the theoretical coverage probabilities.\n\nIf the calibration is good, the empirical and theoretical values should match closely. If not, it suggests that either:\n\n-   The log-normal assumption is inadequate\n\n-   The quantile interpretation of the LLM's bounds is incorrect\n\n-   Or there are systematic biases (e.g., skewed sampling, outliers, etc.)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define theoretical cumulative probabilities to test calibration\ncalibration_probs <- c(0.01, seq(0.05, 0.95, 0.05), 0.99)\n\n# For each quantile level, compute predicted price threshold and empirical coverage\nempirical_cdfs <- sapply(calibration_probs, function(p) {\n  predicted_threshold <- with(product_prices, exp(p1_log_mu + p1_log_sigma * qnorm(p)))\n  mean(product_prices$price_usd < predicted_threshold)\n})\n\n# Assemble calibration data frame\ncalibration_df <- data.frame(\n  theoretical_cdf = calibration_probs,\n  empirical_cdf = empirical_cdfs\n)\n\n# Plot calibration curve\nggplot(calibration_df, aes(x = theoretical_cdf, y = empirical_cdf)) +\n  geom_point() + geom_line() +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dotted\", color = \"red\") +\n  labs(\n    x = \"Target quantile (log-normal model)\",\n    y = \"Observed proportion below quantile\",\n    title = \"Calibration Plot: Log-normal Model vs. Observed Prices\"\n  ) +\n  theme_bw()\n```\n:::\n\n\n\nIt seems that the probability estimates are well-calibrated. Each theoretical quantile corresponds to an approximately equal empirical proportion.\n\n### Shifted Log-Normal Model\n\n-   While the simple log-normal model appears to do a decent job of accounting for individual product price distributions, the log-normal has support on the entire real line, which means that all positive prices are possible, even if they are not very likely.\n-   In reality, this may lead to an excessive amount of probability mass being allocated to unrealistically small prices.\n-   As a solution, it may make sense to model individual product prices as *shifted log-normals.*\n\n$$ log(\\text{lower} - delta) = \\mu + z_{0.3} \\cdot \\sigma $$ $$ log(\\text{mode} - delta) = \\mu -\\sigma^2 $$ $$ log(\\text{median} - delta) = \\mu + z_{0.5} \\cdot \\sigma $$ $$ log(\\text{upper} - delta) = \\mu + z_{0.8} \\cdot \\sigma $$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define z-scores for assumed quantile boundaries of the elicited range\nz_lower <- qnorm(0.3)\nz_upper <- qnorm(0.8)\n\n# Calibrate log-normal parameters assuming lower and upper are 30% and 80% quantiles\nproduct_prices <- \n  py$product_prices_pd %>%\n  filter(!is.na(lower) & !is.na(upper) & !is.na(price_usd)) %>%\n  mutate(\n    p2_delta = (log(upper) - log(lower)) / (z_upper - z_lower),\n    p2_log_sigma = (log(upper) - log(lower)) / (z_upper - z_lower),\n    p2_log_mu = log(lower) - p1_log_sigma * z_lower\n  )\n```\n:::\n\n\n\nWe then validate this calibration by checking how well the empirical price data agrees with the implied distribution. Specifically, we:\n\n1.  Use the calibrated $\\mu$ and $\\sigma$ to compute a range of quantiles.\n\n2.  For each theoretical quantile, we calculate the proportion of real prices that fall under it.\n\n3.  We compare these empirical proportions to the theoretical coverage probabilities.\n\nIf the calibration is good, the empirical and theoretical values should match closely. If not, it suggests that either:\n\n-   The log-normal assumption is inadequate\n\n-   The quantile interpretation of the LLM's bounds is incorrect\n\n-   Or there are systematic biases (e.g., skewed sampling, outliers, etc.)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define theoretical cumulative probabilities to test calibration\ncalibration_probs <- c(0.01, seq(0.05, 0.95, 0.05), 0.99)\n\n# For each quantile level, compute predicted price threshold and empirical coverage\nempirical_cdfs <- sapply(calibration_probs, function(p) {\n  predicted_threshold <- with(product_prices, exp(p1_log_mu + p1_log_sigma * qnorm(p)))\n  mean(product_prices$price_usd < predicted_threshold)\n})\n\n# Assemble calibration data frame\ncalibration_df <- data.frame(\n  theoretical_cdf = calibration_probs,\n  empirical_cdf = empirical_cdfs\n)\n\n# Plot calibration curve\nggplot(calibration_df, aes(x = theoretical_cdf, y = empirical_cdf)) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dotted\", color = \"red\") +\n  labs(\n    x = \"Target quantile (log-normal model)\",\n    y = \"Observed proportion below quantile\",\n    title = \"Calibration Plot: Log-normal Model vs. Observed Prices\"\n  ) +\n  theme_bw()\n```\n:::\n\n\n\nIt seems that the probability estimates are well-calibrated. Each theoretical quantile corresponds to an approximately equal empirical proportion.\n\n## Repository\n\nAll data and source code are available here: üëâ <https://github.com/plogacev/case_studies/tree/main/price_distribution_elicitation>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}